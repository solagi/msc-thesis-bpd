{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras_tuner import Hyperband\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from data_preparation import prepare_x_data, get_Y_labels, reshape_Y, reshape_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "x_train_visual = prepare_x_data('../Data/LLDs_video_openface/train',',', 5, scaler)\n",
    "x_train_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y TRAIN labels\n",
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train_visual),1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_visual(hp):\n",
    "    # Define input layer.\n",
    "    input = Input(shape=(None, 465))\n",
    "\n",
    "    # Define hidden layer.\n",
    "    tcn_v = TCN(nb_filters=hp.Int('v_nb_filters', min_value=1, max_value=465, step=1), \n",
    "                kernel_size=hp.Choice('v_kernel_size', [1,2,4,8,16,32,64,128]), \n",
    "                dilations=(128,256,512,1024), \n",
    "                padding=hp.Choice('v_padding', ['causal', 'same']), \n",
    "                nb_stacks=hp.Choice('v_nb_stacks', [1,2]), \n",
    "                use_batch_norm=False, \n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=False, \n",
    "                use_skip_connections=True, \n",
    "                dropout_rate=hp.Choice('v_dropout_rate', [1e-2, 1e-3, 1e-4]), \n",
    "                return_sequences=False, \n",
    "                input_shape=(None, 465))(input)\n",
    "\n",
    "    # Define output layer.\n",
    "    output = Dense(1, activation='linear')(tcn_v)\n",
    "\n",
    "    # Define optimizer and show summary.\n",
    "    model = keras.Model(inputs=[input], outputs=[output])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_audio(hp):\n",
    "    # Define input layer.\n",
    "    input = Input(shape=(None, 23))\n",
    "\n",
    "    # Define hidden layer.\n",
    "    tcn_a = TCN(nb_filters=hp.Int('a_nb_filters', min_value=1, max_value=23, step=1), \n",
    "                kernel_size=hp.Choice('a_kernel_size', [1,2,4,8,16,32,64,128]), \n",
    "                dilations=(128,256,512,1024), \n",
    "                padding=hp.Choice('a_padding', ['causal', 'same']), \n",
    "                nb_stacks=hp.Choice('a_nb_stacks', [1,2]), \n",
    "                use_batch_norm=False, \n",
    "                use_layer_norm=False, \n",
    "                use_weight_norm=False,\n",
    "                use_skip_connections=True, \n",
    "                dropout_rate=hp.Choice('a_dropout_rate', [1e-2, 1e-3, 1e-4]), \n",
    "                return_sequences=False, \n",
    "                input_shape=(None, 23))(input)\n",
    "\n",
    "\n",
    "    # Define output layer.\n",
    "    output = Dense(1, activation='linear')(tcn_a)\n",
    "\n",
    "    # Define optimizer and show summary.\n",
    "    model = keras.Model(inputs=[input], outputs=[output])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define tuner. A new tuner is created for every file.\n",
    "tuner_v = Hyperband(\n",
    "    hypermodel=build_model_visual, \n",
    "    objective='loss', \n",
    "    max_epochs=50, \n",
    "    factor=3, \n",
    "    project_name='TCN_Tuner_Visual'\n",
    ")\n",
    "\n",
    "tuner_a = Hyperband(\n",
    "    hypermodel=build_model_audio, \n",
    "    objective='loss', \n",
    "    max_epochs=50, \n",
    "    factor=3, \n",
    "    project_name='TCN_Tuner_Audio'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model one file at a time.\n",
    "#Train visual data tuner\n",
    "index_v = 0\n",
    "for train_visual in x_train_visual:\n",
    "    train_visual = reshape_X(train_visual)\n",
    "\n",
    "    tuner_v.search(train_visual, y_train[index_v], epochs=10, batch_size=len(train_visual), callbacks=[early_stop]) \n",
    "    index_v += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model one file at a time.\n",
    "#Train audio data tuner\n",
    "index_a = 0\n",
    "for train_audio in x_train_audio:\n",
    "    train_audio = reshape_X(train_audio)\n",
    "\n",
    "    tuner_a.search(train_audio, y_train[index_a], epochs=10, batch_size=len(train_audio), callbacks=[early_stop]) \n",
    "    index_a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get df from all tuner searches\n",
    "def get_hp_df(tunerdir):\n",
    "    rootdir = tunerdir\n",
    "    hp_values = []\n",
    "    #Get learned hyperparameters for every file (trial) and append to a list\n",
    "    for trial in os.listdir(rootdir):\n",
    "        pathdir = os.path.join(rootdir, trial)\n",
    "        filedir = os.path.join(pathdir, 'trial.json')\n",
    "        \n",
    "        if os.path.isdir(pathdir): #looking only for trial subfolders\n",
    "            with open(filedir) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                values = data['hyperparameters']['values'] #get learned hyperparameters\n",
    "                hp_values.append(values) #append to list\n",
    "        \n",
    "    #Transform to dataframe\n",
    "    hp_df = pd.DataFrame(hp_values)\n",
    "\n",
    "    return hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average hyperparameter values for both modalities\n",
    "hpdf_multi_v = get_hp_df('../TCN/TCN_Tuner_Visual')\n",
    "hpdf_multi_a = get_hp_df('../TCN/TCN_Tuner_Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\" Average hyperparameters for each data modality.\n",
    "--------FOR VISUAL DATA:\"\"\")\n",
    "hpdf_multi_v.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\" Average hyperparameters for each data modality.\n",
    "--------FOR AUDIO DATA:\"\"\")\n",
    "hpdf_multi_a.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f9b3525b118e40fd235adf7264fd2675d7ebc5ac85828864061321fde00e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
