{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from tcn import TCN\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_preparation import prepare_x_data, get_Y_labels, unscale_Y, reshape_Y, reshape_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation includes: <br>\n",
    "<ul>\n",
    "  <li>selecting necessary features from source files</li>\n",
    "  <li>creating combined dataset for the model training</li>\n",
    "  <li>reshaping data for model training.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler)\n",
    "\n",
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train),1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = prepare_x_data('../Data/LLDs_audio_eGeMAPS/dev',';', 2, scaler) \n",
    "\n",
    "y_test = get_Y_labels('../Data/labels_metadata.csv', 0, 60, scaler)\n",
    "y_test = reshape_Y(y_test,len(x_test),1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the longest sequence length.\n",
    "len_dict = {}\n",
    "\n",
    "\n",
    "for idx, df in enumerate(x_train):\n",
    "    len_dict.update({idx:len(df)})\n",
    "\n",
    "max_len = max(len_dict, key=len_dict.get)\n",
    "\n",
    "max_len = {max_len:len_dict.get(max_len)}\n",
    "\n",
    "print(f'Longest sequence {max_len} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed model for temporal convolutional neural network architecture for multi-modal dataset. Both data modalities are concatenated together before the last Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model.\n",
    "model = Sequential()\n",
    "model.add(TCN(nb_filters=12, kernel_size=33, dilations=(256,512,1024,2048), padding='causal', nb_stacks=1,\n",
    "                use_batch_norm=False, use_layer_norm=False, use_weight_norm=False, use_skip_connections=True, dropout_rate=0.005, return_sequences=False, input_shape=(None, 23)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Define optimizer and show summary.\n",
    "model.compile(optimizer=Adam(learning_rate=0.004), loss='mse', metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model=model, show_dtype=False, show_layer_names=True, show_shapes=True, to_file='TCN_audio.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training setup is based on an iterative approach where model is trained one file at a time, then learned parameters are saved and loaded in the next iterative step. This setup is necessary due to the fact that source files does not have an uniform size and differ in number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model one file at a time.\n",
    "train_index = 0\n",
    "val_index = 0\n",
    "loss = {}\n",
    "train_eval = []\n",
    "train_loss = []\n",
    "train_mae = []\n",
    "\n",
    "for train in x_train:\n",
    "\n",
    "    train = np.array(train).reshape((1, train.shape[0], -1))\n",
    "    history = model.fit(x=train, y=y_train[train_index], epochs=10, shuffle=False, batch_size=32, verbose=0, callbacks=early_stop)\n",
    "    loss.update({train_index:history.history})\n",
    "\n",
    "    train_index += 1\n",
    "    \n",
    "    model.save(r'TCN_audio', include_optimizer=True) # Save model configuration to Saved_models.\n",
    "    model = load_model(r'TCN_audio', custom_objects={'TCN':TCN}) # Load model configuration from Saved_models.\n",
    "\n",
    "    scores = model.evaluate([train], y_train[val_index], verbose = 0)\n",
    "    train_eval.append(scores)\n",
    "    train_loss.append(scores[0])\n",
    "    train_mae.append(scores[1])\n",
    "\n",
    "    val_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_loss = sum(train_loss) / len(train_loss)\n",
    "avg_train_mae = sum(train_mae) / len(train_mae)\n",
    "print(\"Train loss visual (avg):\", avg_train_loss, \"Train MAE visual (avg):\", avg_train_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation is performed on subset taken from test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_test[:30].copy()\n",
    "y_val = y_test[:30].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = []\n",
    "eval_mae = []\n",
    "eval_visual = []\n",
    "index = 0\n",
    "\n",
    "for input in x_val:\n",
    "    input = reshape_X(input)\n",
    "    scores = model.evaluate(input, y_val[index], verbose = 0)\n",
    "    \n",
    "    eval_visual.append(scores)\n",
    "    eval_loss.append(scores[0])\n",
    "    eval_mae.append(scores[1])\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_eval_loss = sum(eval_loss) / len(eval_loss)\n",
    "avg_eval_mae = sum(eval_mae) / len(eval_mae)\n",
    "print(\"Validation loss visual (avg):\", avg_eval_loss, \"Validation MAE visual (avg):\", avg_eval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Scaled YMRS value\")\n",
    "plt.plot(eval_loss, label=\"MSE\")\n",
    "plt.plot(eval_mae, label=\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YMRS prediction and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is made on different subset taken from the test dataset. Then actual and predicted YMRS values are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test  = x_test[30:].copy()\n",
    "y_actual = y_test[30:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "pred_eval = []\n",
    "pred_loss = []\n",
    "pred_mae = []\n",
    "test_index = 0\n",
    "\n",
    "for file in x_test:\n",
    "    file = np.array(file).reshape(1, file.shape[0], -1)\n",
    "\n",
    "    pred = model.predict(file)\n",
    "\n",
    "    prediction.append(pred)\n",
    "    scores = model.evaluate(file, y_actual[test_index], verbose=0)\n",
    "    pred_eval.append(scores)\n",
    "    pred_loss.append(scores[0])\n",
    "    pred_mae.append(scores[1])\n",
    "\n",
    "\n",
    "    test_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred_loss = sum(pred_loss) / len(pred_loss)\n",
    "avg_pred_mae = sum(pred_mae) / len(pred_mae)\n",
    "print(\"Prediction loss visual (avg):\", avg_pred_loss, \"Prediction MAE visual (avg):\", avg_pred_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.array(prediction).reshape(-1, 1)\n",
    "y_actual = y_actual.reshape(-1, 1)\n",
    "\n",
    "prediction = unscale_Y(prediction,scaler)\n",
    "y_actual = unscale_Y(y_actual,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data=np.column_stack((y_actual, prediction)), columns=['y_actual','y_pred'])\n",
    "pred_df['pred_error'] = pred_df['y_actual'] - pred_df['y_pred']\n",
    "pred_df = pred_df.sort_values(by=['y_actual']).reset_index()\n",
    "pred_df['y_actual'] = pred_df['y_actual'].apply(np.int64)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(pred_df.y_actual, pred_df.y_pred)\n",
    "mae = mean_absolute_error(pred_df.y_actual, pred_df.y_pred)\n",
    "\n",
    "mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot x = actual, y = predicted\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(pred_df.y_actual, pred_df.y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot x = actual, y = actual - predicted\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction error')\n",
    "plt.scatter(pred_df.y_actual, pred_df.pred_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Test subject IDs\")\n",
    "plt.ylabel(\"Target value (YMRS)\")\n",
    "plt.plot(pred_df.y_actual, label=\"Actual\")\n",
    "plt.plot(pred_df.y_pred, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f9b3525b118e40fd235adf7264fd2675d7ebc5ac85828864061321fde00e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
