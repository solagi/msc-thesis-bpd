{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras_tuner import Hyperband\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from data_preparation import prepare_x_data, get_Y_labels, reshape_Y, reshape_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "x_train_visual = prepare_x_data('../Data/LLDs_video_openface/train',',', 5, scaler)\n",
    "x_train_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y TRAIN labels\n",
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train_visual),1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # Define input layer.\n",
    "    inputA = Input(shape=(None, 465))\n",
    "    inputB = Input(shape=(None, 23))\n",
    "\n",
    "    # Define hidden layer.\n",
    "    tcn_v = TCN(nb_filters=hp.Int('v_nb_filters', min_value=1, max_value=465, step=1), \n",
    "                kernel_size=hp.Choice('v_kernel_size', [1,2,4,8,16,32,64,128]), \n",
    "                dilations=(128,256,512,1024,2048), \n",
    "                padding=hp.Choice('a_padding', ['causal', 'same']), \n",
    "                nb_stacks=hp.Choice('v_nb_stacks', [1,2]), \n",
    "                use_batch_norm=False, \n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=False, \n",
    "                use_skip_connections=True, \n",
    "                dropout_rate=hp.Choice('v_dropout_rate', [1e-2, 1e-3, 1e-4]), \n",
    "                return_sequences=False, \n",
    "                input_shape=(None, 465))(inputA)\n",
    "\n",
    "    tcn_a = TCN(nb_filters=hp.Int('a_nb_filters', min_value=1, max_value=23, step=1), \n",
    "                kernel_size=hp.Choice('a_kernel_size', [1,2,4,8,16,32,64,128]), \n",
    "                dilations=(128,256,512,1024,2048), \n",
    "                padding=hp.Choice('a_padding', ['causal', 'same']), \n",
    "                nb_stacks=hp.Choice('a_nb_stacks', [1,2]), \n",
    "                use_batch_norm=False, \n",
    "                use_layer_norm=False, \n",
    "                use_weight_norm=False,\n",
    "                use_skip_connections=True, \n",
    "                dropout_rate=hp.Choice('a_dropout_rate', [1e-2, 1e-3, 1e-4]), \n",
    "                return_sequences=False, \n",
    "                input_shape=(None, 23))(inputB)\n",
    "\n",
    "\n",
    "    # Define output layer.\n",
    "    output_v = Dense(8, activation='relu')(tcn_v)\n",
    "    output_a = Dense(8, activation='relu')(tcn_a)\n",
    "\n",
    "    combined_input = concatenate([output_v, output_a])\n",
    "\n",
    "    output = Dense(1)(combined_input)\n",
    "\n",
    "    # Define optimizer and show summary.\n",
    "    model = keras.Model(inputs=[inputA, inputB], outputs=[output])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define tuner. A new tuner is created for every file.\n",
    "tuner = Hyperband(\n",
    "    hypermodel=build_model, \n",
    "    objective='loss', \n",
    "    max_epochs=50, \n",
    "    factor=3, \n",
    "    # directory='TCN_Tuner', \n",
    "    project_name='TCN_Tuner_Multi'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model one file at a time.\n",
    "#Train visual data tuner\n",
    "index = 0\n",
    "for train_visual, train_audio in zip(x_train_visual, x_train_audio):\n",
    "    train_visual = reshape_X(train_visual)\n",
    "    train_audio = reshape_X(train_audio)\n",
    "\n",
    "    tuner.search([train_visual, train_audio], y_train[index], epochs=10, callbacks=[early_stop]) \n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get df from all tuner searches\n",
    "def get_hp_df(tunerdir):\n",
    "    rootdir = tunerdir\n",
    "    hp_values = []\n",
    "    #Get learned hyperparameters for every file (trial) and append to a list\n",
    "    for trial in os.listdir(rootdir):\n",
    "        pathdir = os.path.join(rootdir, trial)\n",
    "        filedir = os.path.join(pathdir, 'trial.json')\n",
    "        \n",
    "        if os.path.isdir(pathdir): #looking only for trial subfolders\n",
    "            with open(filedir) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                values = data['hyperparameters']['values'] #get learned hyperparameters\n",
    "                hp_values.append(values) #append to list\n",
    "        \n",
    "    #Transform to dataframe\n",
    "    hp_df = pd.DataFrame(hp_values)\n",
    "\n",
    "    return hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average hyperparameter values for both modalities\n",
    "hpdf_multi = get_hp_df('../TCN/TCN_Tuner_Multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\" Average hyperparameters for each data modality.\n",
    "--------FOR BOTH MODAL DATA:\"\"\")\n",
    "hpdf_multi.mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7357180ab0aea027c2b76ff246d615b9a5a4459a76ec15419f48cf45c2c81d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
