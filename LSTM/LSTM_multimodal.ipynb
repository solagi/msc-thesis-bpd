{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines LSTM model setup trained on both data modalities - audio and visual data combined together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from data_preparation import prepare_x_data, get_Y_labels, reshape_Y, reshape_X, unscale_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation includes: <br>\n",
    "<ul>\n",
    "  <li>selecting necessary features from source files</li>\n",
    "  <li>creating combined dataset for the model training</li>\n",
    "  <li>reshaping data for model training.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data - audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_visual = prepare_x_data('../Data/LLDs_video_openface/train',',', 5, scaler)\n",
    "x_train_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_visual = prepare_x_data('../Data/LLDs_video_openface/dev',',', 5, scaler) \n",
    "x_test_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/dev',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data - YMRS score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train_visual),1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = get_Y_labels('../Data/labels_metadata.csv', 0, 60, scaler)\n",
    "y_test = reshape_Y(y_test,len(x_test_visual),1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed model for LSTM recurrent neural network architecture for multi-modal dataset. Both data modalities are concatenated together before the last Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_input = keras.Input(shape=(None,465), name=\"visual\")\n",
    "audio_input = keras.Input(shape=(None,23), name=\"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_features = layers.LSTM(units = 207, input_shape=(None, 465), return_sequences=True)(visual_input)\n",
    "visual_features = layers.Dropout(0.004)(visual_features)\n",
    "visual_features = layers.LSTM(units = 207, input_shape=(None, 207), return_sequences=False)(visual_features)\n",
    "visual_features = layers.Dropout(0.004)(visual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = layers.LSTM(units = 12, input_shape=(None,23), return_sequences=True)(audio_input)\n",
    "audio_features = layers.Dropout(0.004)(audio_features)\n",
    "audio_features = layers.LSTM(units = 11, input_shape=(None,12), return_sequences=False)(audio_features)\n",
    "audio_features = layers.Dropout(0.004)(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.concatenate([visual_features, audio_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(1, activation='linear')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =layers.Dense(1, name=\"ymrs\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs=[visual_input, audio_input],\n",
    "    outputs=[y_pred]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.004),\n",
    "    loss='mse',           \n",
    "    metrics= [keras.metrics.MeanAbsoluteError()] #['mean_absolute_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model=model, show_dtype=True, show_layer_names=True, show_shapes=True, to_file='LSTM_multimodal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training setup is based on an iterative approach where model is trained one file at a time, then learned parameters are saved and loaded in the next iterative step. This setup is necessary due to the fact that source files does not have an uniform size and differ in number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = 0\n",
    "val_index = 0\n",
    "\n",
    "loss = {}\n",
    "train_eval = []\n",
    "train_loss = []\n",
    "train_mae = []\n",
    "\n",
    "for train_visual, train_audio in zip(x_train_visual, x_train_audio):    \n",
    "        train_visual = np.array(train_visual).reshape((1, train_visual.shape[0], -1))\n",
    "        train_audio = np.array(train_audio).reshape((1, train_audio.shape[0], -1))\n",
    "                \n",
    "        history = model.fit(\n",
    "            [train_visual, train_audio], \n",
    "            y_train[train_index],\n",
    "            epochs=10,\n",
    "        )\n",
    "\n",
    "        loss.update({train_index:history.history})\n",
    "\n",
    "        train_index += 1\n",
    "\n",
    "        model.save(r'LSTM_train_multimodal', include_optimizer = True)\n",
    "        model = keras.models.load_model(r'LSTM_train_multimodal')\n",
    "\n",
    "        scores = model.evaluate([train_visual, train_audio], y_train[train_index], verbose = 0)\n",
    "        train_eval.append(scores)\n",
    "        train_loss.append(scores[0])\n",
    "        train_mae.append(scores[1])\n",
    "        \n",
    "        val_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model evaluation - train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_loss = sum(train_loss) / len(train_loss)\n",
    "avg_train_mae = sum(train_mae) / len(train_mae)\n",
    "print(\"Train loss (avg):\", avg_train_loss, \"Train MAE (avg):\", avg_train_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Scaled YMRS value\")\n",
    "plt.plot(train_loss, label=\"MSE\")\n",
    "plt.plot(train_mae, label=\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation - validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset taken from test data is defined as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_visual, x_val_audio = x_test_visual[:30], x_test_audio[:30]\n",
    "y_val = y_test[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = []\n",
    "eval_mae = []\n",
    "eval_index = 0\n",
    "\n",
    "for input_visual, input_audio in zip(x_val_visual, x_val_audio):\n",
    "    input_visual = reshape_X(input_visual)\n",
    "    input_audio = reshape_X(input_audio)\n",
    "\n",
    "    scores = model.evaluate(\n",
    "        [input_visual,input_audio], \n",
    "        y_val[eval_index],\n",
    "        verbose = 0)\n",
    "        \n",
    "    eval_loss.append(scores[0])\n",
    "    eval_mae.append(scores[1])\n",
    "    \n",
    "    eval_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_eval_loss = sum(eval_loss) / len(eval_loss)\n",
    "avg_eval_mae = sum(eval_mae) / len(eval_mae)\n",
    "print(\"Validation loss (avg):\", avg_eval_loss, \"Validation MAE (avg):\", avg_eval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Scaled YMRS value\")\n",
    "plt.plot(eval_loss, label=\"MSE\")\n",
    "plt.plot(eval_mae, label=\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is made on different subset taken from the test dataset. Then actual and predicted YMRS values are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_visual, x_pred_audio = x_test_visual[30:], x_test_audio[30:]\n",
    "y_pred_actual = y_test[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = []\n",
    "\n",
    "pred_scores = []\n",
    "pred_loss = []\n",
    "pred_mae = []\n",
    "\n",
    "pred_index = 0\n",
    "\n",
    "\n",
    "for test_visual, test_audio in zip(x_pred_visual, x_pred_audio):\n",
    "    test_visual = np.array(test_visual).reshape((1, test_visual.shape[0], -1))\n",
    "    test_audio = np.array(test_audio).reshape((1, test_audio.shape[0], -1))\n",
    "    \n",
    "    pred_y = y_prediction.append(model.predict([test_visual, test_audio]))\n",
    "    \n",
    "    scores = model.evaluate([test_visual, test_audio], y_pred_actual[pred_index], verbose=0)\n",
    "    pred_scores.append(scores)\n",
    "    pred_loss.append(scores[0])\n",
    "    pred_mae.append(scores[1])\n",
    "    \n",
    "    pred_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model evaluation - prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred_loss = sum(pred_loss) / len(pred_loss)\n",
    "avg_pred_mae = sum(pred_mae) / len(pred_mae)\n",
    "print(\"Prediction loss (avg):\", avg_pred_loss, \"Prediction MAE (avg):\", avg_pred_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Scaled YMRS value\")\n",
    "plt.plot(pred_loss, label=\"MSE\")\n",
    "plt.plot(pred_mae, label=\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual vs predicted comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = np.array(y_prediction).reshape(-1, 1)\n",
    "y_pred_actual = np.array(y_pred_actual).reshape(-1, 1)\n",
    "\n",
    "y_prediction = unscale_Y(y_prediction, scaler)\n",
    "y_pred_actual = unscale_Y(y_pred_actual, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data=np.column_stack((y_pred_actual,y_prediction)),columns=['y_actual','y_pred'])\n",
    "pred_df['pred_error'] = pred_df['y_actual'] - pred_df['y_pred']\n",
    "pred_df = pred_df.sort_values(by=['y_actual']).reset_index()\n",
    "pred_df['y_actual'] = pred_df['y_actual'].apply(np.int64)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.plot('y_actual', 'y_pred', kind='scatter')\n",
    "plt.xlabel(\"Actual YMRS\")\n",
    "plt.ylabel(\"Predicted YMRS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.plot('y_actual', 'pred_error', kind='scatter')\n",
    "plt.xlabel(\"Actual YMRS\")\n",
    "plt.ylabel(\"Prediction error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Test subject IDs\")\n",
    "plt.ylabel(\"Target value (YMRS)\")\n",
    "plt.plot(pred_df['y_actual'], label=\"Actual\")\n",
    "plt.plot(pred_df['y_pred'], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f9b3525b118e40fd235adf7264fd2675d7ebc5ac85828864061321fde00e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
