{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines hyperparameter tuning for LSTM model designed for multi-modal dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_tuner import Hyperband\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from data_preparation import prepare_x_data, get_Y_labels, reshape_Y, reshape_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data - audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_visual = prepare_x_data('../Data/LLDs_video_openface/train',',', 5, scaler)\n",
    "x_train_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data - YMRS score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train_visual),1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuner setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \n",
    "    # Hyperparameters for tuning\n",
    "    hp_units_visual_1 = hp.Int('units_visual_1', min_value=1, max_value=465, step=1)\n",
    "    hp_units_visual_2 = hp.Int('units_visual_2', min_value=1, max_value=465, step=1)\n",
    "\n",
    "    hp_units_audio_1 = hp.Int('units_audio_1', min_value=1, max_value=23, step=1)\n",
    "    hp_units_audio_2 = hp.Int('units_audio_2', min_value=1, max_value=23, step=1)\n",
    "\n",
    "    hp_droput_visual = hp.Choice('dropout_visual', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_droput_audio = hp.Choice('dropout_audio', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) #learning rate for the optimizer\n",
    "    \n",
    "    \"\"\"\n",
    "    Multi modal LSTM setup\n",
    "    \"\"\"\n",
    "    # Defining model layers\n",
    "    visual_input = keras.Input(shape=(None,465), name=\"visual\")\n",
    "    audio_input = keras.Input(shape=(None,23), name=\"audio\")\n",
    "    \n",
    "    visual_features = layers.LSTM(units = hp_units_visual_1, input_shape=(None, 465), return_sequences=True)(visual_input)\n",
    "    visual_features = layers.Dropout(hp_droput_visual)(visual_features)\n",
    "    visual_features = layers.LSTM(units = hp_units_visual_2, input_shape=(None, hp_units_visual_1), return_sequences=False)(visual_features)\n",
    "    visual_features = layers.Dropout(hp_droput_visual)(visual_features)\n",
    "\n",
    "    audio_features = layers.LSTM(units = hp_units_audio_1, input_shape=(None,23), return_sequences=True)(audio_input)\n",
    "    audio_features = layers.Dropout(hp_droput_audio)(audio_features)\n",
    "    audio_features = layers.LSTM(units = hp_units_audio_2, input_shape=(None,hp_units_audio_1), return_sequences=False)(audio_features)\n",
    "    visual_features = layers.Dropout(hp_droput_audio)(visual_features)\n",
    "\n",
    "    x = layers.concatenate([visual_features, audio_features])\n",
    "    x = layers.Dense(1, activation='linear')(x)\n",
    "    \n",
    "    # Defining model output\n",
    "    y_pred =layers.Dense(1, name=\"ymrs\")(x)\n",
    "    \n",
    "    # Initializing the model\n",
    "    model = keras.Model(\n",
    "    inputs=[visual_input, audio_input],\n",
    "    outputs=[y_pred]\n",
    "    )\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mse',           \n",
    "        metrics=['mean_absolute_error']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilize tuners\n",
    "\n",
    "tuner = Hyperband(\n",
    "    model_builder,\n",
    "    objective = 'loss',\n",
    "    max_epochs = 50, \n",
    "    factor = 3, \n",
    "    project_name = 'Hp_tuner_multi'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for train_visual, train_audio in zip(x_train_visual, x_train_audio):\n",
    "    train_visual = reshape_X(train_visual)\n",
    "    train_audio = reshape_X(train_audio)\n",
    "\n",
    "    tuner.search([train_visual, train_audio], y_train[index], epochs=10, callbacks=[stop_early]) \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the final hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach of finding the final hyperparameters for the model is based on extracting the average value from all tuner search iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining learned hyperparameters from every iteration in one dataset\n",
    "\n",
    "def get_hp_df(tunerdir):\n",
    "    rootdir = tunerdir\n",
    "    hp_values = []\n",
    "    #Get learned hyperparameters for every file (trial) and append to a list\n",
    "    for trial in os.listdir(rootdir):\n",
    "        pathdir = os.path.join(rootdir, trial)\n",
    "        filedir = os.path.join(pathdir, 'trial.json')\n",
    "        \n",
    "        if os.path.isdir(pathdir): #looking only for trial subfolders\n",
    "            with open(filedir) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                values = data['hyperparameters']['values'] #get learned hyperparameters\n",
    "                hp_values.append(values) #append to list\n",
    "        \n",
    "    #Transform to dataframe\n",
    "    hp_df = pd.DataFrame(hp_values)\n",
    "\n",
    "    return hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get hyperparameter values for both modalities\n",
    "hpdf_multi = get_hp_df('../LSTM/Hp_tuner_multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hyperparameters for the multi-modal LSTM setup:\")\n",
    "hpdf_multi.mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7357180ab0aea027c2b76ff246d615b9a5a4459a76ec15419f48cf45c2c81d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
