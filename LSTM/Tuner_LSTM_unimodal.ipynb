{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines hyperparameter tuning for LSTM model designed for uni-modal dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from data_preparation import prepare_x_data, get_Y_labels, reshape_Y, reshape_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data - audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_visual = prepare_x_data('../Data/LLDs_video_openface/train',',', 5, scaler)\n",
    "x_train_audio = prepare_x_data('../Data/LLDs_audio_eGeMAPS/train',';', 2, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data - YMRS score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_Y_labels('../Data/labels_metadata.csv', 60, 164, scaler)\n",
    "y_train = reshape_Y(y_train,len(x_train_visual),1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuner setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_visual(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Hyperparameters for tuning\n",
    "    hp_dense_units_1 = hp.Int('units_1', min_value=1, max_value=465, step=1)\n",
    "    hp_dense_units_2 = hp.Int('units_2', min_value=1, max_value=465, step=1)\n",
    "    hp_droput = hp.Choice('dropout', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) #learning rate for the optimizer\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "                        units = hp_dense_units_1, \n",
    "                        input_shape=(None,465), \n",
    "                        return_sequences=True \n",
    "                    ))\n",
    "    model.add(layers.Dropout(hp_droput))\n",
    "    model.add(layers.LSTM(\n",
    "                        units = hp_dense_units_2, \n",
    "                        input_shape=(None,hp_dense_units_1), \n",
    "                        return_sequences=False \n",
    "                    ))\n",
    "    model.add(layers.Dropout(hp_droput))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', \n",
    "                  metrics=[keras.metrics.MeanAbsoluteError()] ,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  ) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_audio(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    hp_dense_units_1 = hp.Int('units_1', min_value=1, max_value=23, step=1)\n",
    "    hp_dense_units_2 = hp.Int('units_2', min_value=1, max_value=23, step=1)\n",
    "    hp_droput = hp.Choice('dropout', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) #learning rate for the optimizer\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "                        units = hp_dense_units_1, \n",
    "                        input_shape=(None,23), \n",
    "                        return_sequences=True \n",
    "                    ))\n",
    "    model.add(layers.Dropout(hp_droput))\n",
    "    model.add(layers.LSTM(\n",
    "                        units = hp_dense_units_2, \n",
    "                        input_shape=(None,hp_dense_units_1), \n",
    "                        return_sequences=False \n",
    "                    ))\n",
    "    model.add(layers.Dropout(hp_droput))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', \n",
    "                  metrics=[keras.metrics.MeanAbsoluteError()] ,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  ) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilize tuners - for video and audio modality seperately\n",
    "\n",
    "tuner_visual = kt.Hyperband(\n",
    "    model_builder_visual,\n",
    "    objective = 'loss',\n",
    "    max_epochs = 50,\n",
    "    factor = 3,\n",
    "    project_name = 'Hp_tuner_visual'\n",
    ")\n",
    "\n",
    "tuner_audio = kt.Hyperband(\n",
    "    model_builder_audio,\n",
    "    objective = 'loss',\n",
    "    max_epochs = 50, \n",
    "    factor = 3,\n",
    "    project_name = 'Hp_tuner_audio'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train audio data tuner\n",
    "index = 0\n",
    "for file in x_train_audio:\n",
    "    file = reshape_X(file)\n",
    "    tuner_audio.search(\n",
    "        file, \n",
    "        y_train[index], \n",
    "        epochs=10,  \n",
    "        batch_size = len(file), \n",
    "        callbacks=[stop_early]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train visual data tuner\n",
    "index = 0\n",
    "for file in x_train_visual:\n",
    "    file = reshape_X(file)\n",
    "    tuner_visual.search(\n",
    "        file, \n",
    "        y_train[index], \n",
    "        epochs=10, \n",
    "        batch_size = len(file),\n",
    "        callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the final hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach of finding the final hyperparameters for the model is based on extracting the average value from all tuner search iterations for each modality seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining learned hyperparameters from every iteration in one dataset\n",
    "\n",
    "def get_hp_df(tunerdir):\n",
    "    rootdir = tunerdir\n",
    "    hp_values = []\n",
    "    #Get learned hyperparameters for every file (trial) and append to a list\n",
    "    for trial in os.listdir(rootdir):\n",
    "        pathdir = os.path.join(rootdir, trial)\n",
    "        filedir = os.path.join(pathdir, 'trial.json')\n",
    "        \n",
    "        if os.path.isdir(pathdir): #looking only for trial subfolders\n",
    "            with open(filedir) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                values = data['hyperparameters']['values'] #get learned hyperparameters\n",
    "                hp_values.append(values) #append to list\n",
    "        \n",
    "    #Transform to dataframe\n",
    "    hp_df = pd.DataFrame(hp_values)\n",
    "\n",
    "    return hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get hyperparameter values for both modalities\n",
    "hpdf_visual = get_hp_df('../LSTM/Hp_tuner_visual')\n",
    "hpdf_audio = get_hp_df('../LSTM/Hp_tuner_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\" Hyperparameters for the LSTM model for each data modality.\n",
    "--------FOR VISUAL DATA:\"\"\")\n",
    "print(hpdf_visual.mean())\n",
    "\n",
    "print(\"--------FOR AUDIO DATA:\")\n",
    "print(hpdf_audio.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44cccd652f83914016010e04b52e3797fff9e1f470c3e376f0fe1456ae66b3b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
